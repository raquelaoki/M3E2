{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "official-solid",
   "metadata": {},
   "source": [
    "# Spring 2021\n",
    "\n",
    "## Raquel Aoki\n",
    "\n",
    "Starting the project\n",
    "\n",
    "\n",
    "Source: https://github.com/JiajingZ/CopulaSensitivity\n",
    "\n",
    "Comments: \n",
    "- 7.1 Section data is in R. \n",
    "- 7.2 Section is the GWAS study from Parkca, and the deconfounder. The data generated is different from Blei paper. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compound-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.2 GWAS simulated study // sparse effects setting\n",
    "#https://github.com/raquelaoki/ParKCa/blob/master/src/datapreprocessing.py\n",
    "\n",
    "def sim_genes_TGP(Fs, ps, n_hapmapgenes, n_causes, n_units, S, D, randseed):\n",
    "    '''\n",
    "    #Adapted from Deconfounder's authors\n",
    "    generate the simulated data\n",
    "    input:\n",
    "        - Fs, ps, n_hapmapgenes: not adopted in this example\n",
    "        - n_causes = integer\n",
    "        - n_units = m (columns)\n",
    "        - S: PCA output n x 2\n",
    "    '''\n",
    "    np.random.seed(randseed)\n",
    "\n",
    "    S = expit(S)\n",
    "    Gammamat = np.zeros((n_causes, 3))\n",
    "    Gammamat[:,0] = 0.2*npr.uniform(size=n_causes) #0.45\n",
    "    Gammamat[:,1] = 0.2*npr.uniform(size=n_causes) #0.45\n",
    "    Gammamat[:,2] = 0.05*np.ones(n_causes)\n",
    "    S = np.column_stack((S[npr.choice(S.shape[0],size=n_units,replace=True),], \\\n",
    "        np.ones(n_units)))\n",
    "    F = S.dot(Gammamat.T)\n",
    "    #it was 2 instead of 1: goal is make SNPs binary\n",
    "    G = npr.binomial(1, F)\n",
    "    #unobserved group\n",
    "    lambdas = KMeans(n_clusters=3, random_state=123).fit(S).labels_\n",
    "    sG = sparse.csr_matrix(G)\n",
    "    return G, lambdas\n",
    "\n",
    "\n",
    "def generate_samples(SIMULATIONS,n_units,n_causes):\n",
    "    '''\n",
    "    Input:\n",
    "    SIMULATIONS: number of datasets to be produced\n",
    "    n_units, n_causes: dimentions\n",
    "    Output (pickle format):\n",
    "    snp_simulated datasets\n",
    "    y: output simulated and truecases for each datset are together in a single matrix\n",
    "    Note: There are options to load the data from vcf format and run the pca\n",
    "    Due running time, we save the files and load from the pca.txt file\n",
    "    '''\n",
    "    #ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/hd_genotype_chip/\n",
    "    #tgp_pca2.txt created in https://github.com/raquelaoki/ParKCa/blob/master/src/datapreprocessing.py\n",
    "    S = np.loadtxt('data_s//tgp_pca2.txt', delimiter=',')\n",
    "\n",
    "    sim_y = []\n",
    "    sim_tc = []\n",
    "    for sim in range(SIMULATIONS):\n",
    "        G0, lambdas = sim_genes_TGP([], [], 0 , n_causes, n_units, S, 3, sim )\n",
    "        G1, tc, y01 = sim_dataset(G0,lambdas, n_causes,n_units,sim)\n",
    "        G = add_colnames(G1,tc)\n",
    "        del G0,G1\n",
    "\n",
    "        G.to_pickle('data_s//snp_simulated_'+str(sim)+'.txt')\n",
    "        sim_y.append(y01)\n",
    "        sim_tc.append(tc)\n",
    "    sim_y = np.transpose(np.matrix(sim_y))\n",
    "    sim_y = pd.DataFrame(sim_y)\n",
    "    sim_y.columns = ['sim_'+str(sim) for sim in range(SIMULATIONS)]\n",
    "\n",
    "    sim_tc = np.transpose(np.matrix(sim_tc))\n",
    "    sim_tc = pd.DataFrame(sim_tc)\n",
    "    sim_tc.columns = ['sim_'+str(sim) for sim in range(SIMULATIONS)]\n",
    "\n",
    "    sim_y.to_pickle('data_s//snp_simulated_y01.txt')\n",
    "    sim_tc.to_pickle('data_s//snp_simulated_truecauses.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-catholic",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Get old data\n",
    "- Read the ammount of causes used by deconfudner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new simulated studies - binary nonlinear\n",
    "#Reference: \n",
    "#https://github.com/JiajingZ/CopulaSensitivity/blob/CopSens/simulation/GaussianT_BinaryY_nonlinearYT/GaussianT_BinaryY_nonlinearYT_RR.R\n",
    "#adapted from R to python\n",
    "#GDP\n",
    "#set seed\n",
    "#variables initialization \n",
    "k = 4 #?\n",
    "s = 1 #?\n",
    "B = [2,0.5, -0.4, 0.2] #?\n",
    "gamma = 2.8\n",
    "sigma2_t, sigma2_y = 1, 1\n",
    "\n",
    "tau_l = [3, -1, 1, -0.06] #linear effect\n",
    "tau_nl = -4 #non linear effect\n",
    "coef_true = tau_l.append(tau_nl)\n",
    "\n",
    "def g_yt(t, tau_l, tau_nl): \n",
    "    '''\n",
    "    t: t is n by k matrix\n",
    "    '''\n",
    "    #in R\n",
    "    \n",
    "    #col 3 \n",
    "    t[3] = [item if item>0 else 0.7*item for item in t[3]] #t[,3] = ifelse(t[,3] > 0, t[,3], 0.7*t[,3])\n",
    "    t = t.dot(tau_l) #t %*% tau_l + t[,1]^2 * tau_nl\n",
    "    t[1] = (np.pow(t[1],2))*tau_nl\n",
    "    \n",
    "    return t\n",
    "\n",
    "n = 80000\n",
    "u = np.random.normal(mu = np.repeat(0,s), sigma = diag(s), n) \n",
    "tr = u.dot(np.transpose(B))\n",
    "tr = tr + np.random.normal(mu = np.repeat(0,k), sigma = sigma2_t*diag(k), n) \n",
    "# y_tilde =  g_yt(t = tr) + u %*% gamma + rnorm(n, mean = 0, sd = sqrt(sigma2_y))????\n",
    "\n",
    "y_tilde =  g_yt(t = tr) + u %*% gamma + rnorm(n, mean = 0, sd = sqrt(sigma2_y))\n",
    "y = ifelse(y_tilde > 0, 1, 0)  ## binary Y\n",
    "tr = data.frame(tr); colnames(tr) = c('t1', 't2', 't3', 't4')\n",
    "y = as.numeric(y)\n",
    "\n",
    "## theoretical values -------------------------------------------------------------\n",
    "coef_mu_u_t <- t(B) %*% solve(B %*% t(B) + sigma2_t * diag(k))\n",
    "sigma_u_t <- as.numeric(sqrt(1 - t(B) %*% solve(B %*% t(B) + sigma2_t * diag(k)) %*% B))\n",
    "sigma_ytilde_t <- as.numeric(sqrt( gamma^2*sigma_u_t^2 + sigma2_y ))\n",
    "sigma_ytilde_t_do <- as.numeric(sqrt( gamma^2 + sigma2_y ))\n",
    "\n",
    "t_choice <- diag(k)\n",
    "t2 = rep(0, k)\n",
    "\n",
    "# true Treatment effect #\n",
    "ytilde_mean_do <- g_yt(rbind(t_choice, t2))\n",
    "y_mean_do <- c(pnorm(ytilde_mean_do/sigma_ytilde_t_do))\n",
    "y_mean_do\n",
    "effect_true <- y_mean_do[1:4]/y_mean_do[5]\n",
    "effect_true\n",
    "\n",
    "# true treatment effect bias #\n",
    "ytilde_mean_do_bias <- c(rbind(t_choice, t2) %*% t(coef_mu_u_t) %*% gamma)\n",
    "\n",
    "# true observed treatment effect #\n",
    "ytilde_mean_obs <- ytilde_mean_do + ytilde_mean_do_bias\n",
    "y_mean_obs <- c(pnorm(ytilde_mean_obs/sigma_ytilde_t))\n",
    "y_mean_obs\n",
    "effect_obs <- y_mean_obs[1:4]/y_mean_obs[5]\n",
    "effect_obs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
