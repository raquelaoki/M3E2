{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "official-solid",
   "metadata": {},
   "source": [
    "# Spring 2021\n",
    "\n",
    "## Raquel Aoki\n",
    "\n",
    "Starting the project\n",
    "\n",
    "\n",
    "Source: https://github.com/JiajingZ/CopulaSensitivity\n",
    "\n",
    "Comments: \n",
    "- 7.1 Section data is in R. \n",
    "- 7.2 Section is the GWAS study from Parkca, and the deconfounder. The data generated is different from Blei paper. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compound-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.2 GWAS simulated study // sparse effects setting\n",
    "#https://github.com/raquelaoki/ParKCa/blob/master/src/datapreprocessing.py\n",
    "\n",
    "def sim_genes_TGP(Fs, ps, n_hapmapgenes, n_causes, n_units, S, D, randseed):\n",
    "    '''\n",
    "    #Adapted from Deconfounder's authors\n",
    "    generate the simulated data\n",
    "    input:\n",
    "        - Fs, ps, n_hapmapgenes: not adopted in this example\n",
    "        - n_causes = integer\n",
    "        - n_units = m (columns)\n",
    "        - S: PCA output n x 2\n",
    "    '''\n",
    "    np.random.seed(randseed)\n",
    "\n",
    "    S = expit(S)\n",
    "    Gammamat = np.zeros((n_causes, 3))\n",
    "    Gammamat[:,0] = 0.2*npr.uniform(size=n_causes) #0.45\n",
    "    Gammamat[:,1] = 0.2*npr.uniform(size=n_causes) #0.45\n",
    "    Gammamat[:,2] = 0.05*np.ones(n_causes)\n",
    "    S = np.column_stack((S[npr.choice(S.shape[0],size=n_units,replace=True),], \\\n",
    "        np.ones(n_units)))\n",
    "    F = S.dot(Gammamat.T)\n",
    "    #it was 2 instead of 1: goal is make SNPs binary\n",
    "    G = npr.binomial(1, F)\n",
    "    #unobserved group\n",
    "    lambdas = KMeans(n_clusters=3, random_state=123).fit(S).labels_\n",
    "    sG = sparse.csr_matrix(G)\n",
    "    return G, lambdas\n",
    "\n",
    "\n",
    "def generate_samples(SIMULATIONS,n_units,n_causes):\n",
    "    '''\n",
    "    Input:\n",
    "    SIMULATIONS: number of datasets to be produced\n",
    "    n_units, n_causes: dimentions\n",
    "    Output (pickle format):\n",
    "    snp_simulated datasets\n",
    "    y: output simulated and truecases for each datset are together in a single matrix\n",
    "    Note: There are options to load the data from vcf format and run the pca\n",
    "    Due running time, we save the files and load from the pca.txt file\n",
    "    '''\n",
    "    #ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/hd_genotype_chip/\n",
    "    #tgp_pca2.txt created in https://github.com/raquelaoki/ParKCa/blob/master/src/datapreprocessing.py\n",
    "    S = np.loadtxt('data_s//tgp_pca2.txt', delimiter=',')\n",
    "\n",
    "    sim_y = []\n",
    "    sim_tc = []\n",
    "    for sim in range(SIMULATIONS):\n",
    "        G0, lambdas = sim_genes_TGP([], [], 0 , n_causes, n_units, S, 3, sim )\n",
    "        G1, tc, y01 = sim_dataset(G0,lambdas, n_causes,n_units,sim)\n",
    "        G = add_colnames(G1,tc)\n",
    "        del G0,G1\n",
    "\n",
    "        G.to_pickle('data_s//snp_simulated_'+str(sim)+'.txt')\n",
    "        sim_y.append(y01)\n",
    "        sim_tc.append(tc)\n",
    "    sim_y = np.transpose(np.matrix(sim_y))\n",
    "    sim_y = pd.DataFrame(sim_y)\n",
    "    sim_y.columns = ['sim_'+str(sim) for sim in range(SIMULATIONS)]\n",
    "\n",
    "    sim_tc = np.transpose(np.matrix(sim_tc))\n",
    "    sim_tc = pd.DataFrame(sim_tc)\n",
    "    sim_tc.columns = ['sim_'+str(sim) for sim in range(SIMULATIONS)]\n",
    "\n",
    "    sim_y.to_pickle('data_s//snp_simulated_y01.txt')\n",
    "    sim_tc.to_pickle('data_s//snp_simulated_truecauses.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-catholic",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Get old data\n",
    "- Read the ammount of causes used by deconfudner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "absent-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u.shape (80000, 1)\n",
      "tr.shape (80000, 4)\n",
      "y_tilde.shape (80000,)\n",
      "[ 0.31192661  0.39449541 -0.46752294  0.18311927]\n"
     ]
    }
   ],
   "source": [
    "#tested \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#new simulated studies - binary nonlinear\n",
    "#Reference: \n",
    "#https://github.com/JiajingZ/CopulaSensitivity/blob/CopSens/simulation/GaussianT_BinaryY_nonlinearYT/GaussianT_BinaryY_nonlinearYT_RR.R\n",
    "#adapted from R to python\n",
    "#GDP\n",
    "#set seed\n",
    "#variables initialization \n",
    "k = 4 #?\n",
    "s = 1 #?\n",
    "B = [2,0.5, -0.4, 0.2] #?\n",
    "gamma = 2.8\n",
    "sigma2_t, sigma2_y = 1, 1\n",
    "\n",
    "tau_l = [3, -1, 1, -0.06] #linear effect\n",
    "tau_nl = -4 #non linear effect\n",
    "coef_true = tau_l.copy()\n",
    "coef_true.append(tau_nl)\n",
    "\n",
    "def g_yt(t, tau_l, tau_nl): \n",
    "    '''\n",
    "    t: t is n by k matrix\n",
    "    '''    \n",
    "    #col 3 \n",
    "    t[2] = [item if item>0 else 0.7*item for item in t[2]] #t[,3] = ifelse(t[,3] > 0, t[,3], 0.7*t[,3])\n",
    "    #print(t.shape, len(tau_l), tau_l)\n",
    "    t = t.dot(tau_l) #t %*% tau_l + t[,1]^2 * tau_nl\n",
    "    t[0] = (pow(t[0],2))*tau_nl\n",
    "    \n",
    "    return t #n x 1\n",
    "\n",
    "\n",
    "#g_yt(np.random.rand(3,k), tau_l, tau_nl)\n",
    "n = 80000\n",
    "u = np.random.normal(loc = 0, scale = 1 , size = n*s).reshape(n,s) #mu = rep(0, s), Sigma = diag(s)\n",
    "print('u.shape',u.shape)\n",
    "\n",
    "tr = np.repeat(u,k).reshape(n,k) * B #n again\n",
    "tr = tr+np.random.normal(loc = 0, scale = pow(sigma2_t,2), size = n*k).reshape(n,k)\n",
    "print('tr.shape', tr.shape)\n",
    "\n",
    "y_tilde = g_yt(tr, tau_l, tau_nl)+(u*gamma).reshape(n,)+ np.random.normal(loc = 0, scale = sigma2_y, size = n)\n",
    "print('y_tilde.shape',y_tilde.shape)\n",
    "y = [1 if item > 0 else 0 for item in y_tilde] #very well balanced\n",
    "\n",
    "tr = pd.DataFrame(tr, columns = ['t1', 't2', 't3', 't4'])\n",
    "\n",
    "aux1 = np.linalg.solve(np.array(B).reshape(k,1)*(np.transpose(B).reshape(1,k)) + sigma2_t*np.identity(k),\n",
    "                              np.repeat(1,k))\n",
    "coef_mu_u_t = np.transpose(B)*aux1\n",
    "print(coef_mu_u_t)\n",
    "## theoretical values -------------------------------------------------------------\n",
    "sigma_u_t = np.sqrt(1-np.transpose(B)*aux1*np.array(B).reshape(k,1))\n",
    "sigma_ytilde_t = np.sqrt(pow(gamma,2)*pow(sigma_u_t,2)+sigma2_y)\n",
    "sigma_ytilde_t_do = np.sqrt( pow(gamma,2) + sigma2_y )\n",
    "\n",
    "print('sigma_u_t.shape',sigma_u_t.shape)\n",
    "print('sigma_ytilde_t.shape', sigma_ytilde_t.shape)\n",
    "print('sigma_ytilde_t_do', sigma_ytilde_t_do)\n",
    "\n",
    "t_choice = np.repeat(1,k)\n",
    "t2 = np.repeat(0, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "public-backup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in progress\n",
    "\n",
    "\n",
    "# true Treatment effect #\n",
    "ytilde_mean_do <- g_yt(rbind(t_choice, t2))\n",
    "y_mean_do <- c(pnorm(ytilde_mean_do/sigma_ytilde_t_do))\n",
    "y_mean_do\n",
    "effect_true <- y_mean_do[1:4]/y_mean_do[5]\n",
    "effect_true\n",
    "\n",
    "# true treatment effect bias #\n",
    "ytilde_mean_do_bias <- c(rbind(t_choice, t2) %*% t(coef_mu_u_t) %*% gamma)\n",
    "\n",
    "# true observed treatment effect #\n",
    "ytilde_mean_obs <- ytilde_mean_do + ytilde_mean_do_bias\n",
    "y_mean_obs <- c(pnorm(ytilde_mean_obs/sigma_ytilde_t))\n",
    "y_mean_obs\n",
    "effect_obs <- y_mean_obs[1:4]/y_mean_obs[5]\n",
    "effect_obs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
