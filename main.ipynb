{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "official-solid",
   "metadata": {},
   "source": [
    "# M3E2\n",
    "\n",
    "## Author: Raquel Aoki\n",
    "\n",
    "Date: Spring 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/raquelaoki/ParKCa.git\n",
    "!git clone https://github.com/raquelaoki/CompBioAndSimulated_Datasets.git\n",
    "#!git clone https://github.com/JakeColtman/bartpy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twenty-substance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Availble: True  device:  cuda\n",
      "Data 0\n",
      "Models 0\n",
      "GWAS simulated data initialized!\n",
      "...  5 true causes and  995  confounders\n",
      "... Treatments:  5  proportions  [0.049, 0.045, 0.065, 0.131, 0.154]\n",
      "... Confounders:  995\n",
      "... Target (y) : 0.378\n",
      "... Sample Size: 1000\n",
      " Data Simulation Done!\n",
      "... Target - proportion of 1s 0.378\n",
      "M3E2: Train Shape  (670, 995) (670, 5)\n",
      "... Model initialization done!\n",
      "... Training\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.710838 0.7795027 0.12966529\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.7108378410339355 7.795026898384094 1.2966528534889221\n",
      "......  0  \n",
      "... Train: loss  17.6 0.13 metric  [0.5       0.5       0.5       0.5       0.5       0.4934663] \n",
      "... Val: loss  13.87 metric  [0.5        0.5        0.5        0.5        0.5        0.56499203]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.6081305 0.65776396 0.113591835\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.60813045501709 6.577639579772949 1.1359183490276337\n",
      "......  15  \n",
      "... Train: loss  14.88 0.12 metric  [0.5        0.93543789 0.66348042 0.7762324  0.5186145  0.69841724] \n",
      "... Val: loss  15.2 metric  [0.5        0.67330918 0.64919355 0.59047203 0.5        0.51116427]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 4.311001 0.4994994 0.09671692\n",
      "CHECKING LOSSES AFTER WEIGHT: 4.311000823974609 4.994994103908539 0.9671691805124283\n",
      "......  30  \n",
      "... Train: loss  12.5 0.12 metric  [0.50104167 0.96730784 0.80315155 0.87693349 0.60260523 0.76346992] \n",
      "... Val: loss  15.78 metric  [0.5        0.5839372  0.59072581 0.56468531 0.546875   0.55342903]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 3.0465097 0.557001 0.106710486\n",
      "CHECKING LOSSES AFTER WEIGHT: 3.0465097427368164 5.57000994682312 1.0671048611402512\n",
      "......  45  \n",
      "... Train: loss  11.44 0.12 metric  [0.62462277 0.99322749 0.88321457 0.89846346 0.60875414 0.80941152] \n",
      "... Val: loss  14.48 metric  [0.67894737 0.61111111 0.46034946 0.68269231 0.55729167 0.60964912]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 3.5475478 0.4876775 0.101239994\n",
      "CHECKING LOSSES AFTER WEIGHT: 3.5475478172302246 4.876775145530701 1.0123999416828156\n",
      "......  60  \n",
      "... Train: loss  10.68 0.11 metric  [0.67442012 0.99637418 0.91160375 0.92568835 0.62066069 0.83034756] \n",
      "... Val: loss  17.08 metric  [0.73157895 0.60567633 0.53897849 0.6284965  0.58333333 0.52033493]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 4.0839887 0.4567419 0.1132259\n",
      "CHECKING LOSSES AFTER WEIGHT: 4.083988666534424 4.567418992519379 1.1322589963674545\n",
      "......  75  \n",
      "... Train: loss  10.23 0.11 metric  [0.76871323 0.99195778 0.91806443 0.9381306  0.61943288 0.85352698] \n",
      "... Val: loss  18.48 metric  [0.69561404 0.58937198 0.5141129  0.58872378 0.609375   0.57356459]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 3.1526134 0.39324123 0.10356439\n",
      "CHECKING LOSSES AFTER WEIGHT: 3.152613401412964 3.932412266731262 1.0356438905000687\n",
      "......  90  \n",
      "... Train: loss  9.53 0.11 metric  [0.82794742 0.99090909 0.93401476 0.96186376 0.62085898 0.90428848] \n",
      "... Val: loss  16.64 metric  [0.49824561 0.55555556 0.55174731 0.60708042 0.578125   0.59051037]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 2.577168 0.46209124 0.101984516\n",
      "CHECKING LOSSES AFTER WEIGHT: 2.5771679878234863 4.6209123730659485 1.0198451578617096\n",
      "......  105  \n",
      "... Train: loss  9.02 0.11 metric  [0.85911392 0.99274493 0.95313158 0.96614954 0.66293719 0.91252155] \n",
      "... Val: loss  17.97 metric  [0.67017544 0.55555556 0.47849462 0.64117133 0.55625    0.53947368]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 3.0078425 0.43317345 0.101442195\n",
      "CHECKING LOSSES AFTER WEIGHT: 3.007842540740967 4.331734478473663 1.0144219547510147\n",
      "......  120  \n",
      "... Train: loss  8.61 0.11 metric  [0.91916806 0.9954447  0.9392068  0.97440829 0.63988727 0.93903313] \n",
      "... Val: loss  16.2 metric  [0.49912281 0.59480676 0.59610215 0.59134615 0.625      0.55283094]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 3.0094602 0.35883746 0.109599985\n",
      "CHECKING LOSSES AFTER WEIGHT: 3.009460210800171 3.5883745551109314 1.095999851822853\n",
      "......  135  \n",
      "... Train: loss  8.32 0.11 metric  [0.95857417 0.99907407 0.95726703 0.95568482 0.62850386 0.93473497] \n",
      "... Val: loss  22.31 metric  [0.53070175 0.55012077 0.5141129  0.66127622 0.63541667 0.56419458]\n",
      "... Loading Best validation (epoch  51 )\n",
      "... Final Metrics - Target\n",
      "...... Train :  0.808\n",
      "...... Val :  0.608\n",
      "...... Test :  0.502\n",
      "Outcome Y [ 0.19822077  0.1730267  -0.22465636 -0.36692846  0.5000646   0.3027083\n",
      "  1.2324636   0.2979143   0.69638515]\n",
      "... CATE\n",
      "Models 1\n",
      "GWAS simulated data initialized!\n",
      "...  5 true causes and  995  confounders\n",
      "... Treatments:  5  proportions  [0.049, 0.045, 0.065, 0.131, 0.154]\n",
      "... Confounders:  995\n",
      "... Target (y) : 0.378\n",
      "... Sample Size: 1000\n",
      " Data Simulation Done!\n",
      "... Target - proportion of 1s 0.378\n",
      "M3E2: Train Shape  (670, 995) (670, 5)\n",
      "... Model initialization done!\n",
      "... Training\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.9888215 0.939144 0.12814905\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.988821506500244 9.391440153121948 1.2814904749393463\n",
      "......  0  \n",
      "... Train: loss  18.74 0.13 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  15.19 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.71108 0.8831442 0.12099629\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.711080074310303 8.83144199848175 1.2099628895521164\n",
      "......  15  \n",
      "... Train: loss  17.85 0.12 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  14.58 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.8300653 0.84975004 0.091444485\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.8300652503967285 8.4975004196167 0.9144448488950729\n",
      "......  30  \n",
      "... Train: loss  17.41 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.42658577] \n",
      "... Val: loss  14.3 metric  [0.5       0.5       0.5       0.5       0.5       0.3847561]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.6880336 0.84220576 0.10281939\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.688033580780029 8.422057628631592 1.0281939059495926\n",
      "......  45  \n",
      "... Train: loss  17.11 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.41466131] \n",
      "... Val: loss  14.1 metric  [0.5       0.5       0.5       0.5       0.5       0.3648374]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.783978 0.8429508 0.09946312\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.78397798538208 8.429508209228516 0.9946312010288239\n",
      "......  60  \n",
      "... Train: loss  17.0 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.41869824] \n",
      "... Val: loss  13.95 metric  [0.5        0.5        0.5        0.5        0.5        0.41544715]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.1981554 0.73277014 0.09518274\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.198155403137207 7.327701449394226 0.9518273919820786\n",
      "......  75  \n",
      "... Train: loss  16.74 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.46432561] \n",
      "... Val: loss  13.88 metric  [0.5        0.5        0.5        0.5        0.5        0.41605691]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.857212 0.76245147 0.10313822\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.857212066650391 7.624514698982239 1.0313822329044342\n",
      "......  90  \n",
      "... Train: loss  16.77 0.11 metric  [0.5        0.5        0.5        0.5        0.5        0.45275758] \n",
      "... Val: loss  13.82 metric  [0.5        0.5        0.5        0.5        0.5        0.43272358]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.606636 0.76856184 0.12608907\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.606636047363281 7.6856184005737305 1.2608906626701355\n",
      "......  105  \n",
      "... Train: loss  16.67 0.11 metric  [0.5        0.5        0.5        0.5        0.5        0.47108347] \n",
      "... Val: loss  13.78 metric  [0.5        0.5        0.5        0.5        0.5        0.43272358]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.229244 0.6660563 0.13511449\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.229244232177734 6.660562753677368 1.3511449098587036\n",
      "......  120  \n",
      "... Train: loss  16.67 0.11 metric  [0.5        0.5        0.5        0.5        0.5        0.50782346] \n",
      "... Val: loss  13.74 metric  [0.5        0.5        0.5        0.5        0.5        0.46666667]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.1717715 0.7411405 0.10640619\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.17177152633667 7.411404848098755 1.0640618950128555\n",
      "......  135  \n",
      "... Train: loss  16.67 0.11 metric  [0.5        0.5        0.5        0.5        0.5        0.50649731] \n",
      "... Val: loss  13.71 metric  [0.5        0.5        0.5        0.5        0.5        0.48333333]\n",
      "... Final Metrics - Target\n",
      "...... Train :  0.587\n",
      "...... Val :  0.293\n",
      "...... Test :  0.485\n",
      "Outcome Y [-4.1320983e-02 -2.3201650e-01 -4.0022150e-02  9.1658056e-02\n",
      "  2.0743623e-01  3.9972786e-02  3.5727835e-06 -4.5042223e-01\n",
      "  6.0687798e-01]\n",
      "... CATE\n",
      "Models 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GWAS simulated data initialized!\n",
      "...  5 true causes and  995  confounders\n",
      "... Treatments:  5  proportions  [0.049, 0.045, 0.065, 0.131, 0.154]\n",
      "... Confounders:  995\n",
      "... Target (y) : 0.378\n",
      "... Sample Size: 1000\n",
      " Data Simulation Done!\n",
      "... Target - proportion of 1s 0.378\n",
      "M3E2: Train Shape  (670, 995) (670, 5)\n",
      "... Model initialization done!\n",
      "... Training\n",
      "CHECKING LOSSES BEFORE WEIGHT: 8.230016 0.94015074 0.11017722\n",
      "CHECKING LOSSES AFTER WEIGHT: 8.230015754699707 9.401507377624512 1.1017721891403198\n",
      "......  0  \n",
      "... Train: loss  17.89 0.13 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  14.7 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.3268895 0.72820914 0.11359765\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.326889514923096 7.282091379165649 1.1359764635562897\n",
      "......  15  \n",
      "... Train: loss  15.88 0.12 metric  [0.57879005 0.5        0.72433061 0.46444883 0.5        0.61796276] \n",
      "... Val: loss  14.62 metric  [0.47454844 0.5        0.60183566 0.51412067 0.5        0.47680818]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.1466 0.7475427 0.110075146\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.146599769592285 7.47542679309845 1.1007514595985413\n",
      "......  30  \n",
      "... Train: loss  14.68 0.12 metric  [0.55671173 0.5        0.67353595 0.62386375 0.5        0.71423504] \n",
      "... Val: loss  13.66 metric  [0.59770115 0.5        0.62062937 0.5449294  0.5        0.52102987]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.411237 0.5339338 0.099378526\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.411236763000488 5.339338183403015 0.9937852621078491\n",
      "......  45  \n",
      "... Train: loss  14.32 0.11 metric  [0.60286602 0.5        0.65519126 0.59628621 0.52941622 0.77523989] \n",
      "... Val: loss  14.68 metric  [0.59195402 0.5        0.52229021 0.5449294  0.4007732  0.49528302]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.0686126 0.7373631 0.12306378\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.068612575531006 7.373631000518799 1.2306378036737442\n",
      "......  60  \n",
      "... Train: loss  13.66 0.12 metric  [0.60120027 0.5        0.67062462 0.60813871 0.49940391 0.81428242] \n",
      "... Val: loss  15.64 metric  [0.5907225  0.5        0.50087413 0.47817715 0.43170103 0.50923742]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.856945 0.5700018 0.099560075\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.856945037841797 5.700017809867859 0.9956007450819016\n",
      "......  75  \n",
      "... Train: loss  12.25 0.11 metric  [0.58060774 0.5        0.69368572 0.6145312  0.5334143  0.89613592] \n",
      "... Val: loss  15.38 metric  [0.62068966 0.5        0.62456294 0.50866496 0.42654639 0.58569182]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.9754877 0.6580231 0.10931782\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.97548770904541 6.580231189727783 1.093178167939186\n",
      "......  90  \n",
      "... Train: loss  11.17 0.11 metric  [0.60484059 0.5        0.7409605  0.62083267 0.5        0.89774235] \n",
      "... Val: loss  19.89 metric  [0.57348112 0.5        0.61582168 0.51476252 0.5        0.48643868]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.4554205 0.47431114 0.093249634\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.45542049407959 4.743111431598663 0.9324963390827179\n",
      "......  105  \n",
      "... Train: loss  9.64 0.11 metric  [0.60939108 0.5        0.84797881 0.60884339 0.5        0.92540241] \n",
      "... Val: loss  26.41 metric  [0.5320197  0.5        0.54152098 0.5330552  0.5        0.53360849]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.6325116 0.027281018 0.101116434\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.632511615753174 0.2728101797401905 1.0111643373966217\n",
      "......  120  \n",
      "... Train: loss  8.41 0.11 metric  [0.62838737 0.5        0.9111842  0.61014334 0.5        0.95604466] \n",
      "... Val: loss  29.05 metric  [0.51477833 0.5        0.49737762 0.48074454 0.5        0.54756289]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.0400248 0.040267732 0.10152765\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.040024757385254 0.4026773199439049 1.0152765363454819\n",
      "......  135  \n",
      "... Train: loss  7.47 0.11 metric  [0.65134829 0.5        0.94968853 0.60869928 0.5        0.99023949] \n",
      "... Val: loss  34.98 metric  [0.52627258 0.5        0.47027972 0.45827985 0.5        0.59119497]\n",
      "... Loading Best validation (epoch  142 )\n",
      "... Final Metrics - Target\n",
      "...... Train :  0.954\n",
      "...... Val :  0.621\n",
      "...... Test :  0.542\n",
      "Outcome Y [ 0.1716358   0.08850822  0.00902773 -0.29558247 -0.38510397  0.4924445\n",
      " -1.1126418   0.9690276   0.01001806]\n",
      "... CATE\n",
      "Data 1\n",
      "Models 0\n",
      "GWAS simulated data initialized!\n",
      "...  5 true causes and  995  confounders\n",
      "... Treatments:  5  proportions  [0.149, 0.14, 0.161, 0.126, 0.049]\n",
      "... Confounders:  995\n",
      "... Target (y) : 0.464\n",
      "... Sample Size: 1000\n",
      " Data Simulation Done!\n",
      "... Target - proportion of 1s 0.464\n",
      "M3E2: Train Shape  (670, 995) (670, 5)\n",
      "... Model initialization done!\n",
      "... Training\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.1168528 0.734331 0.13049224\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.116852760314941 7.343310117721558 1.3049224019050598\n",
      "......  0  \n",
      "... Train: loss  17.31 0.13 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  14.5 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.1132817 0.6111101 0.10604574\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.113281726837158 6.111100912094116 1.0604573786258698\n",
      "......  15  \n",
      "... Train: loss  14.52 0.12 metric  [0.5        0.67016635 0.55844419 0.72304451 0.59028335 0.65381591] \n",
      "... Val: loss  17.55 metric  [0.5        0.64606742 0.50187266 0.6076779  0.51046512 0.52766798]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.0423875 0.4520112 0.08764994\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.04238748550415 4.520111978054047 0.8764994144439697\n",
      "......  30  \n",
      "... Train: loss  12.96 0.12 metric  [0.50094697 0.7897346  0.55734188 0.79292259 0.76922158 0.68043345] \n",
      "... Val: loss  20.68 metric  [0.5        0.66947566 0.54026217 0.70552434 0.44844961 0.53853755]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 4.162992 0.3459296 0.100310616\n",
      "CHECKING LOSSES AFTER WEIGHT: 4.162992000579834 3.459295928478241 1.0031061619520187\n",
      "......  45  \n",
      "... Train: loss  10.6 0.12 metric  [0.65333809 0.84604788 0.61849212 0.8133486  0.84394835 0.89265532] \n",
      "... Val: loss  30.52 metric  [0.6125     0.5838015  0.50749064 0.72331461 0.50968992 0.46462451]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 4.936321 0.28531894 0.09916403\n",
      "CHECKING LOSSES AFTER WEIGHT: 4.936320781707764 2.8531894087791443 0.9916403144598007\n",
      "......  60  \n",
      "... Train: loss  7.48 0.12 metric  [0.76908021 0.861183   0.60583321 0.856618   0.91068063 0.97072035] \n",
      "... Val: loss  28.48 metric  [0.46458333 0.62546816 0.51217228 0.57022472 0.48527132 0.49920949]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 4.2870326 0.18172507 0.104998775\n",
      "CHECKING LOSSES AFTER WEIGHT: 4.287032604217529 1.8172506988048553 1.0499877482652664\n",
      "......  75  \n",
      "... Train: loss  6.19 0.12 metric  [0.81055078 0.86891155 0.59020175 0.88174492 0.9228799  0.98294497] \n",
      "... Val: loss  32.56 metric  [0.43229167 0.48689139 0.40636704 0.67602996 0.47790698 0.45928854]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 3.2937055 0.04336368 0.088542365\n",
      "CHECKING LOSSES AFTER WEIGHT: 3.293705463409424 0.43363679200410843 0.8854236453771591\n",
      "......  90  \n",
      "... Train: loss  5.29 0.12 metric  [0.91853903 0.9082056  0.64049424 0.8903194  0.96154042 0.99463384] \n",
      "... Val: loss  40.58 metric  [0.484375   0.6423221  0.49531835 0.71207865 0.48527132 0.47173913]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 2.7671509 0.003710102 0.11637283\n",
      "CHECKING LOSSES AFTER WEIGHT: 2.76715087890625 0.03710102057084441 1.1637283116579056\n",
      "......  105  \n",
      "... Train: loss  4.81 0.12 metric  [0.88990732 0.89703986 0.63334961 0.91497044 0.99201362 0.99826389] \n",
      "... Val: loss  38.1 metric  [0.47395833 0.57350187 0.54822097 0.5238764  0.45930233 0.45750988]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 4.079058 0.00641965 0.10517757\n",
      "CHECKING LOSSES AFTER WEIGHT: 4.0790581703186035 0.06419649813324213 1.0517756640911102\n",
      "......  120  \n",
      "... Train: loss  4.83 0.12 metric  [0.90029722 0.90887536 0.65576658 0.90524338 0.96836412 0.9985119 ] \n",
      "... Val: loss  42.84 metric  [0.44270833 0.52059925 0.43445693 0.45973783 0.45348837 0.43201581]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 3.8663554 0.02174814 0.11684393\n",
      "CHECKING LOSSES AFTER WEIGHT: 3.8663554191589355 0.21748140454292297 1.1684393137693405\n",
      "......  135  \n",
      "... Train: loss  4.78 0.12 metric  [0.93226984 0.89933942 0.64456078 0.9265992  0.97438167 0.99009664] \n",
      "... Val: loss  44.78 metric  [0.49479167 0.47565543 0.36235955 0.47097378 0.46511628 0.45197628]\n",
      "... Loading Best validation (epoch  111 )\n",
      "... Final Metrics - Target\n",
      "...... Train :  1.0\n",
      "...... Val :  0.458\n",
      "...... Test :  0.504\n",
      "Outcome Y [ 0.26437163  0.14483562 -0.03067741 -0.27195317  0.5031118   0.16964987\n",
      "  1.3170878  -0.4239523   0.6531425 ]\n",
      "... CATE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models 1\n",
      "GWAS simulated data initialized!\n",
      "...  5 true causes and  995  confounders\n",
      "... Treatments:  5  proportions  [0.149, 0.14, 0.161, 0.126, 0.049]\n",
      "... Confounders:  995\n",
      "... Target (y) : 0.464\n",
      "... Sample Size: 1000\n",
      " Data Simulation Done!\n",
      "... Target - proportion of 1s 0.464\n",
      "M3E2: Train Shape  (670, 995) (670, 5)\n",
      "... Model initialization done!\n",
      "... Training\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.4871016 0.78818715 0.12636222\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.4871015548706055 7.881871461868286 1.2636221945285797\n",
      "......  0  \n",
      "... Train: loss  17.86 0.13 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  14.85 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 7.132955 0.89931506 0.10866449\n",
      "CHECKING LOSSES AFTER WEIGHT: 7.132955074310303 8.99315059185028 1.0866449028253555\n",
      "......  15  \n",
      "... Train: loss  17.29 0.12 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  14.41 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.023471 0.75472915 0.10834636\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.023470878601074 7.54729151725769 1.083463579416275\n",
      "......  30  \n",
      "... Train: loss  16.89 0.12 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  14.26 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.813431 0.79196024 0.11331031\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.8134307861328125 7.919602394104004 1.13310307264328\n",
      "......  45  \n",
      "... Train: loss  16.91 0.12 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  14.18 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.391009 0.7555885 0.106267996\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.3910088539123535 7.5558847188949585 1.062679961323738\n",
      "......  60  \n",
      "... Train: loss  16.73 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.48470446] \n",
      "... Val: loss  14.13 metric  [0.5       0.5       0.5       0.5       0.5       0.5444664]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.3833265 0.74957687 0.08775047\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.383326530456543 7.495768666267395 0.8775047212839127\n",
      "......  75  \n",
      "... Train: loss  16.72 0.12 metric  [0.5      0.5      0.5      0.5      0.5      0.501038] \n",
      "... Val: loss  14.1 metric  [0.5       0.5       0.5       0.5       0.5       0.5444664]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.0618258 0.7447391 0.093653634\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.061825752258301 7.447391152381897 0.9365363419055939\n",
      "......  90  \n",
      "... Train: loss  16.64 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.51708958] \n",
      "... Val: loss  14.08 metric  [0.5  0.5  0.5  0.5  0.5  0.55]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.0164514 0.7665066 0.10159152\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.016451358795166 7.665066123008728 1.0159152001142502\n",
      "......  105  \n",
      "... Train: loss  16.62 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.49637767] \n",
      "... Val: loss  14.06 metric  [0.5  0.5  0.5  0.5  0.5  0.55]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.4716864 0.7805801 0.121201456\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.471686363220215 7.805801033973694 1.2120145559310913\n",
      "......  120  \n",
      "... Train: loss  16.65 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.51504011] \n",
      "... Val: loss  14.04 metric  [0.5        0.5        0.5        0.5        0.5        0.59367589]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.3360243 0.776953 0.11067578\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.336024284362793 7.769529819488525 1.1067578196525574\n",
      "......  135  \n",
      "... Train: loss  16.62 0.12 metric  [0.5        0.5        0.5        0.5        0.5        0.52116809] \n",
      "... Val: loss  14.03 metric  [0.5        0.5        0.5        0.5        0.5        0.59367589]\n",
      "... Loading Best validation (epoch  118 )\n",
      "... Final Metrics - Target\n",
      "...... Train :  0.509\n",
      "...... Val :  0.599\n",
      "...... Test :  0.542\n",
      "Outcome Y [-6.2906928e-02  1.5844578e-01  1.5209207e-01  4.4293848e-01\n",
      "  2.0640304e-02  6.4350381e-02  4.2289372e-05 -2.2878833e-01\n",
      "  6.0128236e-01]\n",
      "... CATE\n",
      "Models 2\n",
      "GWAS simulated data initialized!\n",
      "...  5 true causes and  995  confounders\n",
      "... Treatments:  5  proportions  [0.149, 0.14, 0.161, 0.126, 0.049]\n",
      "... Confounders:  995\n",
      "... Target (y) : 0.464\n",
      "... Sample Size: 1000\n",
      " Data Simulation Done!\n",
      "... Target - proportion of 1s 0.464\n",
      "M3E2: Train Shape  (670, 995) (670, 5)\n",
      "... Model initialization done!\n",
      "... Training\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.1804414 0.7569305 0.13157783\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.180441379547119 7.569304704666138 1.3157783448696136\n",
      "......  0  \n",
      "... Train: loss  17.11 0.13 metric  [0.5 0.5 0.5 0.5 0.5 0.5] \n",
      "... Val: loss  14.43 metric  [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.8062553 0.44935152 0.10776128\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.806255340576172 4.493515193462372 1.0776127874851227\n",
      "......  15  \n",
      "... Train: loss  14.54 0.12 metric  [0.52274948 0.5        0.75532257 0.54349282 0.5        0.6462524 ] \n",
      "... Val: loss  15.41 metric  [0.53985507 0.5        0.60929952 0.42692939 0.5        0.48803828]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.6300063 0.5096609 0.10991783\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.630006313323975 5.096608996391296 1.0991782695055008\n",
      "......  30  \n",
      "... Train: loss  13.84 0.12 metric  [0.57696116 0.5        0.69749881 0.58804812 0.5        0.73965786] \n",
      "... Val: loss  16.69 metric  [0.39613527 0.5        0.59963768 0.46018062 0.5        0.44358054]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.190357 0.41546792 0.10914819\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.190357208251953 4.154679179191589 1.0914818942546844\n",
      "......  45  \n",
      "... Train: loss  13.15 0.12 metric  [0.56562563 0.5        0.69725501 0.59846066 0.5        0.82921432] \n",
      "... Val: loss  16.3 metric  [0.48550725 0.5        0.50060386 0.53037767 0.5        0.53229665]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.494236 0.45925015 0.110269144\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.494235992431641 4.592501521110535 1.1026914417743683\n",
      "......  60  \n",
      "... Train: loss  12.1 0.12 metric  [0.5945023  0.59447113 0.6956766  0.56230925 0.5        0.88983974] \n",
      "... Val: loss  17.14 metric  [0.61292271 0.50232558 0.48309179 0.38998358 0.5        0.62001595]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.5937304 0.44890052 0.12246254\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.593730449676514 4.489005208015442 1.2246254086494446\n",
      "......  75  \n",
      "... Train: loss  11.29 0.12 metric  [0.52353965 0.59287761 0.70722965 0.56487001 0.5        0.90784392] \n",
      "... Val: loss  17.49 metric  [0.52475845 0.59379845 0.49939614 0.2955665  0.5        0.61124402]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.9349203 0.34423006 0.11259923\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.934920310974121 3.44230055809021 1.125992313027382\n",
      "......  90  \n",
      "... Train: loss  10.73 0.12 metric  [0.60555901 0.56675845 0.66081966 0.60926596 0.5        0.92629808] \n",
      "... Val: loss  19.93 metric  [0.3852657  0.51550388 0.52113527 0.43842365 0.5        0.6050638 ]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.859951 0.2408255 0.10248493\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.859951019287109 2.4082550406455994 1.0248492658138275\n",
      "......  105  \n",
      "... Train: loss  10.13 0.12 metric  [0.61212984 0.63079244 0.6680275  0.59914427 0.5        0.94134025] \n",
      "... Val: loss  23.93 metric  [0.53442029 0.61550388 0.45350242 0.33251232 0.5        0.54984051]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 5.384529 0.21404144 0.09882607\n",
      "CHECKING LOSSES AFTER WEIGHT: 5.384529113769531 2.1404144167900085 0.9882607311010361\n",
      "......  120  \n",
      "... Train: loss  9.7 0.12 metric  [0.67819994 0.6572718  0.59855669 0.5828666  0.5        0.95238968] \n",
      "... Val: loss  22.53 metric  [0.39613527 0.54883721 0.39915459 0.46715928 0.5        0.53947368]\n",
      "CHECKING LOSSES BEFORE WEIGHT: 6.810821 0.07127851 0.08986594\n",
      "CHECKING LOSSES AFTER WEIGHT: 6.810821056365967 0.7127851247787476 0.8986593782901764\n",
      "......  135  \n",
      "... Train: loss  9.01 0.12 metric  [0.6983518  0.70495299 0.54949    0.6023137  0.5        0.9819066 ] \n",
      "... Val: loss  21.5 metric  [0.46256039 0.53875969 0.51449275 0.34400657 0.5        0.5472488 ]\n",
      "... Loading Best validation (epoch  66 )\n",
      "... Final Metrics - Target\n",
      "...... Train :  0.92\n",
      "...... Val :  0.615\n",
      "...... Test :  0.532\n",
      "Outcome Y [ 0.3055445   0.28347313  0.11704453  0.00314264 -0.2801152   0.29912522\n",
      " -0.89755815  0.97249746  0.03138317]\n",
      "... CATE\n",
      "Time ------ 4.977818822860717 min / 0.08296364704767863 hours ------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import yaml\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, 'src/')\n",
    "#sys.path.insert(0, 'bartpy/')  # https://github.com/JakeColtman/bartpy\n",
    "sys.path.insert(0, 'ParKCa/src/')\n",
    "#from ParKCa.src.train import *\n",
    "from CompBioAndSimulated_Datasets.simulated_data_multicause import *\n",
    "import model_m3e2 as m3e2\n",
    "\n",
    "\n",
    "def main(config_path, seed_models, seed_data):\n",
    "    \"\"\"Start: Parameters Loading\"\"\"\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    params = config['parameters']\n",
    "\n",
    "    # Fix numpy seed for reproducibility\n",
    "    np.random.seed(seed_models)\n",
    "    # Fix random seed for reproducibility\n",
    "    random.seed(seed_models)\n",
    "    # Fix Torch graph-level seed for reproducibility\n",
    "    torch.manual_seed(seed_models)\n",
    "\n",
    "    if 'gwas' in params['data']:\n",
    "\n",
    "        params_b = {'DA': {'k': [15]},\n",
    "                    'CEVAE': {'num_epochs': 100, 'batch': 200, 'z_dim': 10}}\n",
    "\n",
    "        params[\"n_treatments\"] = trykey(params, 'n_treatments', 5)\n",
    "        prop = params[\"n_treatments\"] / (params[\"n_treatments\"] + params['n_covariates'])\n",
    "\n",
    "        sdata_gwas = gwas_simulated_data(prop_tc=prop,\n",
    "                                         pca_path='CompBioAndSimulated_Datasets/data/tgp_pca2.txt',\n",
    "                                         seed=seed_data,\n",
    "                                         n_units=params['n_sample'],\n",
    "                                         n_causes=params[\"n_treatments\"] + params['n_covariates'],\n",
    "                                         true_causes=params[\"n_treatments\"])\n",
    "        X, y, y01, treatement_columns, treatment_effects, group = sdata_gwas.generate_samples()\n",
    "        # Train and Test split use the same seed\n",
    "        params['baselines'] = trykey(params, 'baselines', False)\n",
    "        if params['baselines']:\n",
    "            baselines_results, exp_time, f1_test = baselines(params['baselines_list'], pd.DataFrame(X), y01, params_b,\n",
    "                                                             TreatCols=treatement_columns, timeit=True,\n",
    "                                                             seed=seed_models)\n",
    "        else:\n",
    "            baselines_results, exp_time, f1_test = baselines(['noise'], pd.DataFrame(X), y01, params_b,\n",
    "                                                             TreatCols=treatement_columns, timeit=True,\n",
    "                                                             seed=seed_models)\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y01, test_size=0.33, random_state=seed_models)\n",
    "        print('... Target - proportion of 1s', np.sum(y01) / len(y01))\n",
    "        # Split X1, X2 on GWAS: case with no clinicla variables , X2 = X\n",
    "        X1_cols = []\n",
    "        X2_cols = range(X.shape[1] - len(treatement_columns))\n",
    "\n",
    "        data_nnl = m3e2.data_nn(X_train.values, X_test.values, y_train, y_test, treatement_columns,\n",
    "                                treatment_effects[treatement_columns], X1_cols, X2_cols)\n",
    "        loader_train, loader_val, loader_test, num_features = data_nnl.loader(params['suffle'], params['batch_size'],\n",
    "                                                                              seed_models)\n",
    "        params['pos_weights'] = data_nnl.treat_weights\n",
    "        params['pos_weight_y'] = trykey(params, 'pos_weight_y', 1)\n",
    "        params['hidden1'] = trykey(params, 'hidden1', 64)\n",
    "        params['hidden2'] = trykey(params, 'hidden2', 8)\n",
    "        cate_m3e2, f1_test_ = m3e2.fit_nn(loader_train, loader_val, loader_test, params, treatement_columns,\n",
    "                                          num_features,\n",
    "                                          X1_cols, X2_cols)\n",
    "        print('... CATE')\n",
    "        baselines_results['M3E2'] = cate_m3e2\n",
    "        exp_time['M3E2'] = time.time() - start_time\n",
    "        f1_test['M3E2'] = f1_test_\n",
    "        output = organize_output(baselines_results.copy(), treatment_effects[treatement_columns], exp_time, f1_test)\n",
    "    if 'copula' in params['data']:\n",
    "        params_b = {'DA': {'k': [5]},\n",
    "                    'CEVAE': {'num_epochs': 100, 'batch': 200, 'z_dim': 5}}\n",
    "\n",
    "        sdata_copula = copula_simulated_data(seed=seed_data, n=params['n_sample'], s=params['n_covariates'])\n",
    "        X, y, y01, treatement_columns, treatment_effects = sdata_copula.generate_samples()\n",
    "\n",
    "        if params['baselines']:\n",
    "            baselines_results, exp_time, f1_test = baselines(params['baselines_list'], pd.DataFrame(X), y01, params_b,\n",
    "                                                             TreatCols=treatement_columns, timeit=True,\n",
    "                                                             seed=seed_models)\n",
    "        else:\n",
    "            baselines_results, exp_time, f1_test = baselines(['noise'], pd.DataFrame(X), y01, params_b,\n",
    "                                                             TreatCols=treatement_columns, timeit=True,\n",
    "                                                             seed=seed_models)\n",
    "        start = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y01, test_size=0.33, random_state=seed_models)\n",
    "        X1_cols = []\n",
    "        X2_cols = range(X.shape[1] - len(treatement_columns))\n",
    "        # TODO: add other baselines here to run everything on the same train/testing sets\n",
    "\n",
    "        data_nnl = m3e2.data_nn(X_train, X_test, y_train, y_test, treatement_columns,\n",
    "                                treatment_effects, X1_cols, X2_cols)\n",
    "        loader_train, loader_val, loader_test, num_features = data_nnl.loader(params['suffle'], params['batch_size'],\n",
    "                                                                              seed_models)\n",
    "        params['pos_weights'] = data_nnl.treat_weights\n",
    "        params['pos_weight_y'] = trykey(params, 'pos_weight_y', 1)\n",
    "        params['hidden1'] = trykey(params, 'hidden1', 6)\n",
    "        params['hidden2'] = trykey(params, 'hidden2', 6)\n",
    "\n",
    "        cate_m3e2, f1_test_ = m3e2.fit_nn(loader_train, loader_val, loader_test, params, treatement_columns,\n",
    "                                          num_features,\n",
    "                                          X1_cols, X2_cols)\n",
    "        print('... CATE')\n",
    "        cate = pd.DataFrame({'CATE_M3E2': cate_m3e2, 'True_Effect': treatment_effects})\n",
    "        baselines_results['M3E2'] = cate_m3e2\n",
    "        exp_time['M3E2'] = time.time() - start_time\n",
    "        f1_test['M3E2'] = f1_test_\n",
    "        output = organize_output(baselines_results.copy(), treatment_effects[treatement_columns], exp_time, f1_test)\n",
    "    if 'gwas' not in params['data'] and 'copula' not in params['data']:\n",
    "        print(\n",
    "            \"ERRROR! \\nDataset not recognized. \\nChange the parameter data in your config.yaml file to gwas or copula.\")\n",
    "\n",
    "    name = 'output_' + params['data'][0] + '_' + params['id'] + '.csv'\n",
    "    output['seed_data'] = seed_data\n",
    "    output['seed_models'] = seed_models\n",
    "\n",
    "    return output, name\n",
    "\n",
    "\n",
    "def trykey(params, key, default):\n",
    "    try:\n",
    "        return params[key]\n",
    "    except KeyError:\n",
    "        params[key] = default\n",
    "        return params[key]\n",
    "\n",
    "\n",
    "def baselines(BaselinesList, X, y, ParamsList, seed=63, TreatCols=None, id='', timeit=False):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        X, colnamesX: potential causes and their names\n",
    "        Z, colnamesZ: confounders and their names\n",
    "        y: 01 outcome\n",
    "        causes: name of the potential causes\n",
    "    \"\"\"\n",
    "\n",
    "    if TreatCols is None:\n",
    "        TreatCols = list(range(X.shape[1]))\n",
    "\n",
    "    # check if binary treatments\n",
    "    X01 = X.copy()\n",
    "    for col in TreatCols:\n",
    "        a = X01.iloc[:, col]\n",
    "        if not ((a == 0) | (a == 1)).all():\n",
    "            mean_v = np.mean(X01.iloc[:, col])\n",
    "            X01.iloc[:, col] = [1 if i > mean_v else 0 for i in X01.iloc[:, col]]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    X_train, X_test, y_train, y_test, X_train01, X_test01 = train_test_split(X, y, X01,\n",
    "                                                                             test_size=0.33, random_state=seed)\n",
    "    coef_table = pd.DataFrame(columns=['causes'])\n",
    "    coef_table['causes'] = ['T' + str(i) for i in range(len(TreatCols))]\n",
    "    times, f1_test = {}, {}\n",
    "\n",
    "    if 'DA' in BaselinesList:\n",
    "        start_time = time.time()\n",
    "        from deconfounder import deconfounder_algorithm as DA\n",
    "        ParamsList['DA']['k'] = trykey(ParamsList['DA'], 'k', 15)  # if exploring multiple latent sizes\n",
    "        for k in ParamsList['DA']['k']:\n",
    "            if len(ParamsList['DA']['k']) > 1:\n",
    "                coln = 'DA_' + str(id) + str(k)\n",
    "            else:\n",
    "                coln = 'DA'\n",
    "            model_da = DA(X_train, X_test, y_train, y_test, k, print_=False)\n",
    "            ParamsList['DA']['class_weight'] = trykey(ParamsList['DA'], 'class_weight', {0: 1, 1: 1})\n",
    "            coef, coef_continuos, roc, f1_test['DA'] = model_da.fit(class_weight=ParamsList['DA']['class_weight'])\n",
    "            coef_table[coln] = coef_continuos[TreatCols]\n",
    "        times['DA'] = time.time() - start_time\n",
    "        print('\\nDone!')\n",
    "\n",
    "    if 'BART' in BaselinesList:\n",
    "        start_time = time.time()\n",
    "        from bart import BART as BART\n",
    "        model_bart = BART(X_train01, X_test01, y_train, y_test)\n",
    "        ParamsList['BART']['n_trees'] = trykey(ParamsList['BART'], 'n_trees', 50)\n",
    "        ParamsList['BART']['n_burn'] = trykey(ParamsList['BART'], 'n_burn', 100)\n",
    "        model_bart.fit(n_trees=ParamsList['BART']['n_trees'], n_burn=ParamsList['BART']['n_burn'], print_=False)\n",
    "        print('...... predictions')\n",
    "        coef_table['BART'], f1_test['BART'] = model_bart.cate(TreatCols, print_=False)\n",
    "        times['BART'] = time.time() - start_time\n",
    "        print('\\nDone!')\n",
    "\n",
    "    if 'CEVAE' in BaselinesList:\n",
    "        print('\\n\\n Learner: CEVAE')\n",
    "        start_time = time.time()\n",
    "        from cevae import CEVAE as CEVAE\n",
    "        print('Note: Treatments should be the first columns of X')\n",
    "        ParamsList['CEVAE']['epochs'] = trykey(ParamsList['CEVAE'], 'epochs', 100)\n",
    "        ParamsList['CEVAE']['batch'] = trykey(ParamsList['CEVAE'], 'batch', 200)\n",
    "        ParamsList['CEVAE']['z_dim'] = trykey(ParamsList['CEVAE'], 'z_dim', 5)\n",
    "\n",
    "        confeatures, binfeatures = [], []\n",
    "        for col in range(X_train01.shape[1]):\n",
    "            a = X_train01.iloc[:, col]\n",
    "            if not ((a == 0) | (a == 1)).all():\n",
    "                confeatures.append(col)\n",
    "            else:\n",
    "                binfeatures.append(col)\n",
    "\n",
    "        print('... length con and bin features', len(confeatures), len(binfeatures))\n",
    "        model_cevae = CEVAE(X_train01, X_test01, y_train, y_test, TreatCols,\n",
    "                            binfeats=binfeatures, contfeats=confeatures,\n",
    "                            epochs=ParamsList['CEVAE']['epochs'],\n",
    "                            batch=ParamsList['CEVAE']['batch'],\n",
    "                            z_dim=ParamsList['CEVAE']['z_dim'])\n",
    "        coef_table['CEVAE'], f1_test['CEVAE'] = model_cevae.fit_all(print_=False)\n",
    "        times['CEVAE'] = time.time() - start_time\n",
    "        print('\\nDone!')\n",
    "\n",
    "    if not timeit:\n",
    "        return coef_table\n",
    "    else:\n",
    "        return coef_table, times, f1_test\n",
    "\n",
    "\n",
    "def organize_output(experiments, true_effect, exp_time=None, f1_scores=None):\n",
    "    \"\"\"\n",
    "    Important: experiments, experiments times and f1 scores should be in the same order\n",
    "    Parameters\n",
    "    ----------\n",
    "    experiments\n",
    "    true_effect\n",
    "    exp_time\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    Treatments = experiments['causes']\n",
    "    experiments.set_index('causes', inplace=True)\n",
    "    experiments['TrueTreat'] = true_effect\n",
    "    Treatments_cate = np.transpose(experiments)\n",
    "    BaselinesNames = experiments.columns\n",
    "    mae = []\n",
    "    for col in BaselinesNames:\n",
    "        dif = np.abs(experiments[col] - experiments['TrueTreat'])\n",
    "        mae.append(np.nanmean(dif))\n",
    "    output = pd.DataFrame({'Method': BaselinesNames, 'MAE': mae})\n",
    "    exp_time['TrueTreat'] = 0\n",
    "    f1_scores['TrueTreat'] = 0\n",
    "    if f1_scores is not None:\n",
    "        output['F1_Test'] = [f1_scores[m] for m in output['Method'].values]\n",
    "    if exp_time is not None:\n",
    "        output['Time(s)'] = [exp_time[m] for m in output['Method'].values]\n",
    "\n",
    "    out = pd.DataFrame(Treatments_cate, columns=Treatments)\n",
    "    out.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return pd.concat((output, out), 1)\n",
    "\n",
    "\n",
    "colab = False\n",
    "notebook = True\n",
    "arg = {'config_path': 'config1.yaml',\n",
    "       'seed_models': 3,\n",
    "       'seed_data': 2,\n",
    "       }\n",
    "if colab:\n",
    "    arg['path'] = '/content/'\n",
    "    arg['config_path'] = arg['path']+arg['config_path']\n",
    "else:\n",
    "    arg['path'] = ''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    if notebook:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Cuda Availble:\", torch.cuda.is_available(), \" device: \", device)\n",
    "        for j in range(arg['seed_data']):\n",
    "            print('Data',j)\n",
    "            for i in range(arg['seed_models']):\n",
    "                print('Models',i)\n",
    "                if i == 0 and j == 0:\n",
    "                    output, name = main(config_path=arg['config_path'], seed_models=i, seed_data=j)\n",
    "                else:\n",
    "                    output_, name = main(config_path=arg['config_path'], seed_models=i, seed_data=j)\n",
    "                    output = pd.concat([output, output_], 0, ignore_index=True)\n",
    "    else:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Cuda Availble:\", torch.cuda.is_available(), \" device: \", device)\n",
    "        for j in range(sys.argv[3]):\n",
    "            print('Data', j)\n",
    "            for i in range(sys.argv[2]):\n",
    "                print('Models', i)\n",
    "                if i == 0:\n",
    "                    output, name = main(config_path=sys.argv[1], seed_models=i+1, seed_data=j+1)\n",
    "                else:\n",
    "                    output_, name = main(config_path=sys.argv[1], seed_models=i+1, seed_data=j+1)\n",
    "                    output = pd.concat([output, output_], 0, ignore_index=True)\n",
    "\n",
    "    output.to_csv(name)\n",
    "    end_time = time.time() - start_time\n",
    "    end_time_m = end_time / 60\n",
    "    end_time_h = end_time_m / 60\n",
    "    print(\"Time ------ {} min / {} hours ------\".format(end_time_m, end_time_h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEVAE IS KILLING IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hungarian-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>MAE</th>\n",
       "      <th>F1_Test</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>seed_data</th>\n",
       "      <th>seed_models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M3E2</td>\n",
       "      <td>0.349089</td>\n",
       "      <td>0.434483</td>\n",
       "      <td>48.068610</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.173027</td>\n",
       "      <td>-0.224656</td>\n",
       "      <td>-0.366928</td>\n",
       "      <td>0.500065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrueTreat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441013</td>\n",
       "      <td>0.100039</td>\n",
       "      <td>0.244684</td>\n",
       "      <td>0.560223</td>\n",
       "      <td>0.466889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M3E2</td>\n",
       "      <td>0.365423</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>46.823281</td>\n",
       "      <td>-0.041321</td>\n",
       "      <td>-0.232017</td>\n",
       "      <td>-0.040022</td>\n",
       "      <td>0.091658</td>\n",
       "      <td>0.207436</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TrueTreat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441013</td>\n",
       "      <td>0.100039</td>\n",
       "      <td>0.244684</td>\n",
       "      <td>0.560223</td>\n",
       "      <td>0.466889</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M3E2</td>\n",
       "      <td>0.444873</td>\n",
       "      <td>0.343137</td>\n",
       "      <td>47.496845</td>\n",
       "      <td>0.171636</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>-0.295582</td>\n",
       "      <td>-0.385104</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TrueTreat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441013</td>\n",
       "      <td>0.100039</td>\n",
       "      <td>0.244684</td>\n",
       "      <td>0.560223</td>\n",
       "      <td>0.466889</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M3E2</td>\n",
       "      <td>0.166265</td>\n",
       "      <td>0.469055</td>\n",
       "      <td>47.194874</td>\n",
       "      <td>0.264372</td>\n",
       "      <td>0.144836</td>\n",
       "      <td>-0.030677</td>\n",
       "      <td>-0.271953</td>\n",
       "      <td>0.503112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TrueTreat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>-0.152939</td>\n",
       "      <td>-0.132043</td>\n",
       "      <td>-0.268242</td>\n",
       "      <td>0.216352</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M3E2</td>\n",
       "      <td>0.394281</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>46.061867</td>\n",
       "      <td>-0.062907</td>\n",
       "      <td>0.158446</td>\n",
       "      <td>0.152092</td>\n",
       "      <td>0.442938</td>\n",
       "      <td>0.020640</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TrueTreat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>-0.152939</td>\n",
       "      <td>-0.132043</td>\n",
       "      <td>-0.268242</td>\n",
       "      <td>0.216352</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M3E2</td>\n",
       "      <td>0.310779</td>\n",
       "      <td>0.509554</td>\n",
       "      <td>45.986393</td>\n",
       "      <td>0.305544</td>\n",
       "      <td>0.283473</td>\n",
       "      <td>0.117045</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>-0.280115</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TrueTreat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>-0.152939</td>\n",
       "      <td>-0.132043</td>\n",
       "      <td>-0.268242</td>\n",
       "      <td>0.216352</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method       MAE   F1_Test    Time(s)        T0        T1        T2  \\\n",
       "0        M3E2  0.349089  0.434483  48.068610  0.198221  0.173027 -0.224656   \n",
       "1   TrueTreat  0.000000  0.000000   0.000000  0.441013  0.100039  0.244684   \n",
       "2        M3E2  0.365423  0.093750  46.823281 -0.041321 -0.232017 -0.040022   \n",
       "3   TrueTreat  0.000000  0.000000   0.000000  0.441013  0.100039  0.244684   \n",
       "4        M3E2  0.444873  0.343137  47.496845  0.171636  0.088508  0.009028   \n",
       "5   TrueTreat  0.000000  0.000000   0.000000  0.441013  0.100039  0.244684   \n",
       "6        M3E2  0.166265  0.469055  47.194874  0.264372  0.144836 -0.030677   \n",
       "7   TrueTreat  0.000000  0.000000   0.000000  0.406086 -0.152939 -0.132043   \n",
       "8        M3E2  0.394281  0.435115  46.061867 -0.062907  0.158446  0.152092   \n",
       "9   TrueTreat  0.000000  0.000000   0.000000  0.406086 -0.152939 -0.132043   \n",
       "10       M3E2  0.310779  0.509554  45.986393  0.305544  0.283473  0.117045   \n",
       "11  TrueTreat  0.000000  0.000000   0.000000  0.406086 -0.152939 -0.132043   \n",
       "\n",
       "          T3        T4  seed_data  seed_models  \n",
       "0  -0.366928  0.500065          0            0  \n",
       "1   0.560223  0.466889          0            0  \n",
       "2   0.091658  0.207436          0            1  \n",
       "3   0.560223  0.466889          0            1  \n",
       "4  -0.295582 -0.385104          0            2  \n",
       "5   0.560223  0.466889          0            2  \n",
       "6  -0.271953  0.503112          1            0  \n",
       "7  -0.268242  0.216352          1            0  \n",
       "8   0.442938  0.020640          1            1  \n",
       "9  -0.268242  0.216352          1            1  \n",
       "10  0.003143 -0.280115          1            2  \n",
       "11 -0.268242  0.216352          1            2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "regular-control",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>F1_Test</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>seed_models</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seed_data</th>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>M3E2</th>\n",
       "      <td>0.386462</td>\n",
       "      <td>0.290457</td>\n",
       "      <td>47.462912</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>-0.085217</td>\n",
       "      <td>-0.190284</td>\n",
       "      <td>0.107466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrueTreat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441013</td>\n",
       "      <td>0.100039</td>\n",
       "      <td>0.244684</td>\n",
       "      <td>0.560223</td>\n",
       "      <td>0.466889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>M3E2</th>\n",
       "      <td>0.290442</td>\n",
       "      <td>0.471241</td>\n",
       "      <td>46.414378</td>\n",
       "      <td>0.169003</td>\n",
       "      <td>0.195585</td>\n",
       "      <td>0.079486</td>\n",
       "      <td>0.058043</td>\n",
       "      <td>0.081212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrueTreat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>-0.152939</td>\n",
       "      <td>-0.132043</td>\n",
       "      <td>-0.268242</td>\n",
       "      <td>0.216352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MAE   F1_Test    Time(s)        T0        T1  \\\n",
       "seed_data Method                                                         \n",
       "0         M3E2       0.386462  0.290457  47.462912  0.109512  0.009839   \n",
       "          TrueTreat  0.000000  0.000000   0.000000  0.441013  0.100039   \n",
       "1         M3E2       0.290442  0.471241  46.414378  0.169003  0.195585   \n",
       "          TrueTreat  0.000000  0.000000   0.000000  0.406086 -0.152939   \n",
       "\n",
       "                           T2        T3        T4  seed_models  \n",
       "seed_data Method                                                \n",
       "0         M3E2      -0.085217 -0.190284  0.107466            1  \n",
       "          TrueTreat  0.244684  0.560223  0.466889            1  \n",
       "1         M3E2       0.079486  0.058043  0.081212            1  \n",
       "          TrueTreat -0.132043 -0.268242  0.216352            1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(['seed_data','Method']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-communications",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-arthur",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-marriage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-escape",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-actor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-importance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-export",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-network",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-sleeping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(2, 2)\n",
    "print('Available devices ', torch.cuda.device_count())\n",
    "print('Current cuda device ', torch.cuda.current_device())\n",
    "cuda = torch.device(0)\n",
    "b = a.cuda()\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-harvest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-actor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-shadow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-policy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-honor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-europe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-domestic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-cologne",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
