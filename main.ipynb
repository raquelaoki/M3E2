{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "official-solid",
   "metadata": {},
   "source": [
    "# M3E2\n",
    "\n",
    "## Author: Raquel Aoki\n",
    "\n",
    "Date: Spring 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/raquelaoki/ParKCa.git\n",
    "!git clone https://github.com/raquelaoki/CompBioAndSimulated_Datasets.git\n",
    "#!git clone https://github.com/JakeColtman/bartpy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-substance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Availble: True  device:  cuda\n",
      "Data 0\n",
      "Models 0\n",
      "GWAS simulated data initialized!\n",
      "...  5 true causes and  995  confounders\n",
      "... Treatments:  5  proportions  [0.66, 0.48, 0.5, 1.88, 1.29]\n",
      "... Confounders:  995\n",
      "... Target (y) : 0.33\n",
      "... Sample Size: 100\n",
      " Data Simulation Done!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import yaml\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, 'src/')\n",
    "#sys.path.insert(0, 'bartpy/')  # https://github.com/JakeColtman/bartpy\n",
    "sys.path.insert(0, 'ParKCa/src/')\n",
    "#from ParKCa.src.train import *\n",
    "from CompBioAndSimulated_Datasets.simulated_data_multicause import *\n",
    "import model_m3e2 as m3e2\n",
    "\n",
    "\n",
    "def main(config_path, seed_models, seed_data):\n",
    "    \"\"\"Start: Parameters Loading\"\"\"\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    params = config['parameters']\n",
    "\n",
    "    # Fix numpy seed for reproducibility\n",
    "    np.random.seed(seed_models)\n",
    "    # Fix random seed for reproducibility\n",
    "    random.seed(seed_models)\n",
    "    # Fix Torch graph-level seed for reproducibility\n",
    "    torch.manual_seed(seed_models)\n",
    "\n",
    "    if 'gwas' in params['data']:\n",
    "\n",
    "        params_b = {'DA': {'k': [15]},\n",
    "                    'CEVAE': {'num_epochs': 100, 'batch': 200, 'z_dim': 10}}\n",
    "\n",
    "        params[\"n_treatments\"] = trykey(params, 'n_treatments', 5)\n",
    "        prop = params[\"n_treatments\"] / (params[\"n_treatments\"] + params['n_covariates'])\n",
    "\n",
    "        sdata_gwas = gwas_simulated_data(prop_tc=prop,\n",
    "                                         pca_path='CompBioAndSimulated_Datasets/data/tgp_pca2.txt',\n",
    "                                         seed=seed_data,\n",
    "                                         n_units=params['n_sample'],\n",
    "                                         n_causes=params[\"n_treatments\"] + params['n_covariates'],\n",
    "                                         true_causes=params[\"n_treatments\"])\n",
    "        X, y, y01, treatement_columns, treatment_effects, group = sdata_gwas.generate_samples()\n",
    "        # Train and Test split use the same seed\n",
    "        params['baselines'] = trykey(params, 'baselines', False)\n",
    "        if params['baselines']:\n",
    "            baselines_results, exp_time, f1_test = baselines(params['baselines_list'], pd.DataFrame(X), y01, params_b,\n",
    "                                                             TreatCols=treatement_columns, timeit=True,\n",
    "                                                             seed=seed_models)\n",
    "        else:\n",
    "            baselines_results, exp_time, f1_test = baselines(['noise'], pd.DataFrame(X), y01, params_b,\n",
    "                                                             TreatCols=treatement_columns, timeit=True,\n",
    "                                                             seed=seed_models)\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y01, test_size=0.33, random_state=seed_models)\n",
    "        print('... Target - proportion of 1s', np.sum(y01) / len(y01))\n",
    "        # Split X1, X2 on GWAS: case with no clinicla variables , X2 = X\n",
    "        X1_cols = []\n",
    "        X2_cols = range(X.shape[1] - len(treatement_columns))\n",
    "\n",
    "        data_nnl = m3e2.data_nn(X_train.values, X_test.values, y_train, y_test, treatement_columns,\n",
    "                                treatment_effects[treatement_columns], X1_cols, X2_cols)\n",
    "        loader_train, loader_val, loader_test, num_features = data_nnl.loader(params['suffle'], params['batch_size'],\n",
    "                                                                              seed_models)\n",
    "        params['pos_weights'] = data_nnl.treat_weights\n",
    "        params['pos_weight_y'] = trykey(params, 'pos_weight_y', 1)\n",
    "        params['hidden1'] = trykey(params, 'hidden1', 64)\n",
    "        params['hidden2'] = trykey(params, 'hidden2', 8)\n",
    "        cate_m3e2, f1_test_ = m3e2.fit_nn(loader_train, loader_val, loader_test, params, treatement_columns,\n",
    "                                          num_features,\n",
    "                                          X1_cols, X2_cols)\n",
    "        print('... CATE')\n",
    "        baselines_results['M3E2'] = cate_m3e2\n",
    "        exp_time['M3E2'] = time.time() - start_time\n",
    "        f1_test['M3E2'] = f1_test_\n",
    "        output = organize_output(baselines_results.copy(), treatment_effects[treatement_columns], exp_time, f1_test)\n",
    "    if 'copula' in params['data']:\n",
    "        params_b = {'DA': {'k': [5]},\n",
    "                    'CEVAE': {'num_epochs': 100, 'batch': 200, 'z_dim': 5}}\n",
    "\n",
    "        sdata_copula = copula_simulated_data(seed=seed_data, n=params['n_sample'], s=params['n_covariates'])\n",
    "        X, y, y01, treatement_columns, treatment_effects = sdata_copula.generate_samples()\n",
    "\n",
    "        if params['baselines']:\n",
    "            baselines_results, exp_time, f1_test = baselines(params['baselines_list'], pd.DataFrame(X), y01, params_b,\n",
    "                                                             TreatCols=treatement_columns, timeit=True,\n",
    "                                                             seed=seed_models)\n",
    "        else:\n",
    "            baselines_results, exp_time, f1_test = baselines(['noise'], pd.DataFrame(X), y01, params_b,\n",
    "                                                             TreatCols=treatement_columns, timeit=True,\n",
    "                                                             seed=seed_models)\n",
    "        start = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y01, test_size=0.33, random_state=seed_models)\n",
    "        X1_cols = []\n",
    "        X2_cols = range(X.shape[1] - len(treatement_columns))\n",
    "        # TODO: add other baselines here to run everything on the same train/testing sets\n",
    "\n",
    "        data_nnl = m3e2.data_nn(X_train, X_test, y_train, y_test, treatement_columns,\n",
    "                                treatment_effects, X1_cols, X2_cols)\n",
    "        loader_train, loader_val, loader_test, num_features = data_nnl.loader(params['suffle'], params['batch_size'],\n",
    "                                                                              seed_models)\n",
    "        params['pos_weights'] = data_nnl.treat_weights\n",
    "        params['pos_weight_y'] = trykey(params, 'pos_weight_y', 1)\n",
    "        params['hidden1'] = trykey(params, 'hidden1', 6)\n",
    "        params['hidden2'] = trykey(params, 'hidden2', 6)\n",
    "\n",
    "        cate_m3e2, f1_test_ = m3e2.fit_nn(loader_train, loader_val, loader_test, params, treatement_columns,\n",
    "                                          num_features,\n",
    "                                          X1_cols, X2_cols)\n",
    "        print('... CATE')\n",
    "        cate = pd.DataFrame({'CATE_M3E2': cate_m3e2, 'True_Effect': treatment_effects})\n",
    "        baselines_results['M3E2'] = cate_m3e2\n",
    "        exp_time['M3E2'] = time.time() - start_time\n",
    "        f1_test['M3E2'] = f1_test_\n",
    "        output = organize_output(baselines_results.copy(), treatment_effects[treatement_columns], exp_time, f1_test)\n",
    "    if 'gwas' not in params['data'] and 'copula' not in params['data']:\n",
    "        print(\n",
    "            \"ERRROR! \\nDataset not recognized. \\nChange the parameter data in your config.yaml file to gwas or copula.\")\n",
    "\n",
    "    name = 'output_' + params['data'][0] + '_' + params['id'] + '.csv'\n",
    "    output['seed_data'] = seed_data\n",
    "    output['seed_models'] = seed_models\n",
    "\n",
    "    return output, name\n",
    "\n",
    "\n",
    "def trykey(params, key, default):\n",
    "    try:\n",
    "        return params[key]\n",
    "    except KeyError:\n",
    "        params[key] = default\n",
    "        return params[key]\n",
    "\n",
    "\n",
    "def baselines(BaselinesList, X, y, ParamsList, seed=63, TreatCols=None, id='', timeit=False):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        X, colnamesX: potential causes and their names\n",
    "        Z, colnamesZ: confounders and their names\n",
    "        y: 01 outcome\n",
    "        causes: name of the potential causes\n",
    "    \"\"\"\n",
    "\n",
    "    if TreatCols is None:\n",
    "        TreatCols = list(range(X.shape[1]))\n",
    "\n",
    "    # check if binary treatments\n",
    "    X01 = X.copy()\n",
    "    for col in TreatCols:\n",
    "        a = X01.iloc[:, col]\n",
    "        if not ((a == 0) | (a == 1)).all():\n",
    "            mean_v = np.mean(X01.iloc[:, col])\n",
    "            X01.iloc[:, col] = [1 if i > mean_v else 0 for i in X01.iloc[:, col]]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    X_train, X_test, y_train, y_test, X_train01, X_test01 = train_test_split(X, y, X01,\n",
    "                                                                             test_size=0.33, random_state=seed)\n",
    "    coef_table = pd.DataFrame(columns=['causes'])\n",
    "    coef_table['causes'] = ['T' + str(i) for i in range(len(TreatCols))]\n",
    "    times, f1_test = {}, {}\n",
    "\n",
    "    if 'DA' in BaselinesList:\n",
    "        start_time = time.time()\n",
    "        from deconfounder import deconfounder_algorithm as DA\n",
    "        ParamsList['DA']['k'] = trykey(ParamsList['DA'], 'k', 15)  # if exploring multiple latent sizes\n",
    "        for k in ParamsList['DA']['k']:\n",
    "            if len(ParamsList['DA']['k']) > 1:\n",
    "                coln = 'DA_' + str(id) + str(k)\n",
    "            else:\n",
    "                coln = 'DA'\n",
    "            model_da = DA(X_train, X_test, y_train, y_test, k, print_=False)\n",
    "            ParamsList['DA']['class_weight'] = trykey(ParamsList['DA'], 'class_weight', {0: 1, 1: 1})\n",
    "            coef, coef_continuos, roc, f1_test['DA'] = model_da.fit(class_weight=ParamsList['DA']['class_weight'])\n",
    "            coef_table[coln] = coef_continuos[TreatCols]\n",
    "        times['DA'] = time.time() - start_time\n",
    "        print('\\nDone!')\n",
    "\n",
    "    if 'BART' in BaselinesList:\n",
    "        start_time = time.time()\n",
    "        from bart import BART as BART\n",
    "        model_bart = BART(X_train01, X_test01, y_train, y_test)\n",
    "        ParamsList['BART']['n_trees'] = trykey(ParamsList['BART'], 'n_trees', 50)\n",
    "        ParamsList['BART']['n_burn'] = trykey(ParamsList['BART'], 'n_burn', 100)\n",
    "        model_bart.fit(n_trees=ParamsList['BART']['n_trees'], n_burn=ParamsList['BART']['n_burn'], print_=False)\n",
    "        print('...... predictions')\n",
    "        coef_table['BART'], f1_test['BART'] = model_bart.cate(TreatCols, print_=False)\n",
    "        times['BART'] = time.time() - start_time\n",
    "        print('\\nDone!')\n",
    "\n",
    "    if 'CEVAE' in BaselinesList:\n",
    "        print('\\n\\n Learner: CEVAE')\n",
    "        start_time = time.time()\n",
    "        from cevae import CEVAE as CEVAE\n",
    "        print('Note: Treatments should be the first columns of X')\n",
    "        ParamsList['CEVAE']['epochs'] = trykey(ParamsList['CEVAE'], 'epochs', 100)\n",
    "        ParamsList['CEVAE']['batch'] = trykey(ParamsList['CEVAE'], 'batch', 200)\n",
    "        ParamsList['CEVAE']['z_dim'] = trykey(ParamsList['CEVAE'], 'z_dim', 5)\n",
    "\n",
    "        confeatures, binfeatures = [], []\n",
    "        for col in range(X_train01.shape[1]):\n",
    "            a = X_train01.iloc[:, col]\n",
    "            if not ((a == 0) | (a == 1)).all():\n",
    "                confeatures.append(col)\n",
    "            else:\n",
    "                binfeatures.append(col)\n",
    "\n",
    "        print('... length con and bin features', len(confeatures), len(binfeatures))\n",
    "        model_cevae = CEVAE(X_train01, X_test01, y_train, y_test, TreatCols,\n",
    "                            binfeats=binfeatures, contfeats=confeatures,\n",
    "                            epochs=ParamsList['CEVAE']['epochs'],\n",
    "                            batch=ParamsList['CEVAE']['batch'],\n",
    "                            z_dim=ParamsList['CEVAE']['z_dim'])\n",
    "        coef_table['CEVAE'], f1_test['CEVAE'] = model_cevae.fit_all(print_=False)\n",
    "        times['CEVAE'] = time.time() - start_time\n",
    "        print('\\nDone!')\n",
    "\n",
    "    if not timeit:\n",
    "        return coef_table\n",
    "    else:\n",
    "        return coef_table, times, f1_test\n",
    "\n",
    "\n",
    "def organize_output(experiments, true_effect, exp_time=None, f1_scores=None):\n",
    "    \"\"\"\n",
    "    Important: experiments, experiments times and f1 scores should be in the same order\n",
    "    Parameters\n",
    "    ----------\n",
    "    experiments\n",
    "    true_effect\n",
    "    exp_time\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    Treatments = experiments['causes']\n",
    "    experiments.set_index('causes', inplace=True)\n",
    "    experiments['TrueTreat'] = true_effect\n",
    "    Treatments_cate = np.transpose(experiments)\n",
    "    BaselinesNames = experiments.columns\n",
    "    mae = []\n",
    "    for col in BaselinesNames:\n",
    "        dif = np.abs(experiments[col] - experiments['TrueTreat'])\n",
    "        mae.append(np.nanmean(dif))\n",
    "    output = pd.DataFrame({'Method': BaselinesNames, 'MAE': mae})\n",
    "    exp_time['TrueTreat'] = 0\n",
    "    f1_scores['TrueTreat'] = 0\n",
    "    if f1_scores is not None:\n",
    "        output['F1_Test'] = [f1_scores[m] for m in output['Method'].values]\n",
    "    if exp_time is not None:\n",
    "        output['Time(s)'] = [exp_time[m] for m in output['Method'].values]\n",
    "\n",
    "    out = pd.DataFrame(Treatments_cate, columns=Treatments)\n",
    "    out.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return pd.concat((output, out), 1)\n",
    "\n",
    "\n",
    "colab = False\n",
    "notebook = True\n",
    "arg = {'config_path': 'config1.yaml',\n",
    "       'seed_models': 10,\n",
    "       'seed_data': 5,\n",
    "       }\n",
    "if colab:\n",
    "    arg['path'] = '/content/'\n",
    "    arg['config_path'] = arg['path']+arg['config_path']\n",
    "else:\n",
    "    arg['path'] = ''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    if notebook:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Cuda Availble:\", torch.cuda.is_available(), \" device: \", device)\n",
    "        for j in range(arg['seed_data']):\n",
    "            print('Data',j)\n",
    "            for i in range(arg['seed_models']):\n",
    "                print('Models',i)\n",
    "                if i == 0 and j == 0:\n",
    "                    output, name = main(config_path=arg['config_path'], seed_models=i, seed_data=j)\n",
    "                else:\n",
    "                    output_, name = main(config_path=arg['config_path'], seed_models=i, seed_data=j)\n",
    "                    output = pd.concat([output, output_], 0, ignore_index=True)\n",
    "    else:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Cuda Availble:\", torch.cuda.is_available(), \" device: \", device)\n",
    "        for j in range(sys.argv[3]):\n",
    "            print('Data', j)\n",
    "            for i in range(sys.argv[2]):\n",
    "                print('Models', i)\n",
    "                if i == 0:\n",
    "                    output, name = main(config_path=sys.argv[1], seed_models=i+1, seed_data=j+1)\n",
    "                else:\n",
    "                    output_, name = main(config_path=sys.argv[1], seed_models=i+1, seed_data=j+1)\n",
    "                    output = pd.concat([output, output_], 0, ignore_index=True)\n",
    "\n",
    "    output.to_csv(name)\n",
    "    end_time = time.time() - start_time\n",
    "    end_time_m = end_time / 60\n",
    "    end_time_h = end_time_m / 60\n",
    "    print(\"Time ------ {} min / {} hours ------\".format(end_time_m, end_time_h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEVAE IS KILLING IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-andrew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-control",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-communications",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-arthur",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-marriage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-escape",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-actor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-importance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-export",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-network",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-sleeping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excess-dollar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  1\n",
      "Current cuda device  0\n",
      "tensor([[ 0.5818,  0.0534],\n",
      "        [ 0.7927, -0.5387]])\n",
      "tensor([[ 0.5818,  0.0534],\n",
      "        [ 0.7927, -0.5387]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(2, 2)\n",
    "print('Available devices ', torch.cuda.device_count())\n",
    "print('Current cuda device ', torch.cuda.current_device())\n",
    "cuda = torch.device(0)\n",
    "b = a.cuda()\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-harvest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-actor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-shadow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-policy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-honor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-europe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-domestic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-cologne",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
