{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "official-solid",
   "metadata": {},
   "source": [
    "# Spring 2021\n",
    "\n",
    "## Raquel Aoki\n",
    "\n",
    "Starting the project\n",
    "\n",
    "\n",
    "Data simulation sources: \n",
    "- https://github.com/JiajingZ/CopulaSensitivity\n",
    "- https://github.com/raquelaoki/ParKCa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sacred-carry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6007580/raoki/M3E2/env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.insert(0,'src/')\n",
    "sys.path.insert(0,'bartpy/') #https://github.com/JakeColtman/bartpy\n",
    "from data_simulation import *\n",
    "from bartpy.sklearnmodel import SklearnModel as bart\n",
    "from bartpy.features.featureimportance import feature_importance\n",
    "from bartpy.features.featureselection import SelectNullDistributionThreshold, SelectSplitProportionThreshold\n",
    "from bartpy.diagnostics.features import *\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "    https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungarian-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_data = copula_simulated_data(s = 10)\n",
    "#tr, u, y_continuous, y_binary = sim_data.get_data()\n",
    "#effect_true, effect_obs, true_treat_obs_effect_01,true_treat_obs_effect= sim_data.get_true_coefs()\n",
    "#sim_data.print_equation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impressive-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the proportion of true causes\n",
    "gwas_data = gwas_simulated_data(1000, 100, 8, prop_tc = 0.05)\n",
    "y, tc, X, col = gwas_data.generate_samples()\n",
    "X = pd.DataFrame(X).sample(frac=1.0).values\n",
    "y = y.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "communist-india",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.21it/s]\n",
      "  2%|▏         | 3/200 [00:00<00:07, 27.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 28.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SklearnModel(n_chains=1, n_jobs=1, n_trees=40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bart(n_chains = 1, n_burn =200, n_trees=40, store_in_sample_predictions=False, n_jobs=1) # Use default parameters\n",
    "model.fit(X, y) # Fit the model\n",
    "#predictions = model.predict() # Make predictions on the train set\n",
    "#out_of_sample_predictions = model.predict(X_test) # Make predictions on new data\n",
    "#y_ = model.predict(X)\n",
    "#thhold = Find_Optimal_Cutoff(y,y_)\n",
    "#y_01 = [0 if item < thhold else 1 for item in y_]\n",
    "#print('\\n...Training set: F1 - ',f1_score(y,y_01))\n",
    "#print('...... confusion matrix: ',confusion_matrix(y,y_01).ravel())\n",
    "#...Training set: F1 -  0.5192743764172335\n",
    "#...... confusion matrix:  [347 232 192 229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-incentive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:00<00:19, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 28.79it/s]\n",
      "  2%|▏         | 3/200 [00:00<00:06, 28.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 29.40it/s]\n",
      "  1%|          | 2/200 [00:00<00:19, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 29.28it/s]\n",
      "  2%|▏         | 3/200 [00:00<00:06, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside print [11.06918753973746, 11.266141699781482] 11.16766461975947\n"
     ]
    }
   ],
   "source": [
    "#Feature_importance: \n",
    "#orginal, null = np.zeros(X.shape[1]),np.zeros(X.shape[1])\n",
    "#for feature in range(X.shape[1]):\n",
    "#    print(feature)\n",
    "    #o, n = \n",
    "feature_importance(model, X, y,0)\n",
    "    ##print(o,n)\n",
    "    #original[feature], null[feature] = o.mean(), n.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-sleeping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cate(y_pred, X, tc, col):\n",
    "    cate_ = []\n",
    "    for i in col: \n",
    "        y0 = np.array(y_)[X.iloc[:,i]==0]\n",
    "        y1 = np.array(y_)[X.iloc[:,i]==1]\n",
    "        cate_.append(y1.mean() - y0.mean())\n",
    "        print(y1.mean() - y0.mean(), tc[i])\n",
    "    pehe = sum(pow(tc[col]-cate_,2))/len(col)\n",
    "    return cate_, pehe\n",
    "\n",
    "cate_, pehe = cate(y_, X, tc, col)\n",
    "#print(cate_)\n",
    "print('PEHE',pehe)#0.1830\n",
    "\n",
    "#for i in col: \n",
    "i = col[2]\n",
    "y0 = y_[X.iloc[:,i]==0]\n",
    "y1 = y_[X.iloc[:,i]==1]\n",
    "print((y1.mean()- y0.mean())/len(y_), tc[i], i, y0.mean(),y1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X.copy()\n",
    "i = col[2]\n",
    "X1.iloc[:,i] = 1-X1.iloc[:,i]\n",
    "y_1 = model.predict(X1)\n",
    "print(tc[i],y_1.mean()-y_.mean() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-shadow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-policy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bartpy.sklearnmodel import SklearnModel\n",
    "from bartpy.features.featureselection import SelectNullDistributionThreshold, SelectSplitProportionThreshold\n",
    "from bartpy.diagnostics.features import *\n",
    "from bartpy.features.featureimportance import feature_importance\n",
    "\n",
    "\n",
    "x = np.linspace(0, 5, 1000)\n",
    "X = np.random.normal(0, 4, size = 1000 * 3).reshape(-1, 3)\n",
    "X[:, 0] = x\n",
    "X = pd.DataFrame(X).sample(frac=1.0).values\n",
    "y = np.random.normal(0, 0.1, size=1000) + np.sin(X[:, 0])\n",
    "model = SklearnModel(n_samples=200, n_burn=50, n_trees=10, store_in_sample_predictions=False, n_jobs=1)\n",
    "model.fit(X, y)\n",
    "original, null = feature_importance(model, X, y, 0)#\n",
    "print(X.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(0, 0.1, size=1000) + np.sin(X[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
