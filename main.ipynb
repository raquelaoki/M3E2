{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "official-solid",
   "metadata": {},
   "source": [
    "# Spring 2021\n",
    "\n",
    "## Raquel Aoki\n",
    "\n",
    "Starting the project\n",
    "\n",
    "\n",
    "Data simulation sources: \n",
    "- https://github.com/JiajingZ/CopulaSensitivity\n",
    "- https://github.com/raquelaoki/ParKCa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sacred-carry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6007580/raoki/M3E2/env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.insert(0,'src/')\n",
    "sys.path.insert(0,'bartpy/') #https://github.com/JakeColtman/bartpy\n",
    "from data_simulation import *\n",
    "#from bartpy.sklearnmodel import SklearnModel as bart\n",
    "#from bartpy.features.featureimportance import feature_importance\n",
    "#from bartpy.features.featureselection import SelectNullDistributionThreshold, SelectSplitProportionThreshold\n",
    "#from bartpy.diagnostics.features import *\n",
    "\n",
    "from bartpy.sklearnmodel import SklearnModel as bart\n",
    "from bartpy.features.featureselection import SelectNullDistributionThreshold, SelectSplitProportionThreshold\n",
    "from bartpy.diagnostics.features import *\n",
    "from bartpy.features.featureimportance import feature_importance\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score,roc_curve,roc_auc_score, accuracy_score\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "    https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungarian-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_data = copula_simulated_data(s = 10)\n",
    "#tr, u, y_continuous, y_binary = sim_data.get_data()\n",
    "#effect_true, effect_obs, true_treat_obs_effect_01,true_treat_obs_effect= sim_data.get_true_coefs()\n",
    "#sim_data.print_equation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressive-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the proportion of true causes\n",
    "gwas_data = gwas_simulated_data(1000, 100, 8, prop_tc = 0.05)\n",
    "y, tc, X, col = gwas_data.generate_samples()\n",
    "X = pd.DataFrame(X).sample(frac=1.0).values\n",
    "#y = y.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "military-marriage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total:  (1000, 100) \n",
      "Covariates:  (1000, 95) \n",
      "Treatments:  (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "T = X[:,col]\n",
    "X1 = np.delete(X,col,1)\n",
    "\n",
    "print(X3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "analyzed-network",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 38.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 48.22it/s]\n",
      "  1%|          | 6/1000 [00:00<00:17, 58.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 63.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 52.97it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n",
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 63.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.14it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n",
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 62.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 50.60it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n",
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 63.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...Training set: F1 -  0.5175438596491229\n",
      "...Training set: acc -  0.56\n",
      "...... confusion matrix: \n",
      " [[324 255]\n",
      " [185 236]]\n",
      "\n",
      "...Random set: F1 -  0.39999999999999997\n",
      "...Random set: acc -  0.502\n",
      "...... confusion matrix: \n",
      " [[336 243]\n",
      " [255 166]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pca = PCA(n_components=5)\n",
    "X3 = np.concatenate((T,pca.fit_transform(X1)),axis = 1)\n",
    "\n",
    "model = bart(n_samples=1000, n_burn=10, n_trees=25, store_in_sample_predictions=False, n_jobs=1) # Use default parameters\n",
    "model.fit(X3, y) # Fit the model\n",
    "y_ = model.predict(X3)\n",
    "thhold = Find_Optimal_Cutoff(y,y_)\n",
    "y_01 = [0 if item < thhold else 1 for item in y_]\n",
    "\n",
    "#random \n",
    "prob = sum(y)/len(y)\n",
    "y_random = [np.random.binomial(1,prob) for item in y_]\n",
    "\n",
    "print('\\n...Training set: F1 - ',f1_score(y,y_01))\n",
    "print('...Training set: acc - ',accuracy_score(y,y_01))\n",
    "print('...... confusion matrix: \\n',confusion_matrix(y,y_01))\n",
    "\n",
    "print('\\n...Random set: F1 - ',f1_score(y,y_random))\n",
    "print('...Random set: acc - ',accuracy_score(y,y_random))\n",
    "print('...... confusion matrix: \\n',confusion_matrix(y,y_random))\n",
    "\n",
    "#...Training set: F1 -  0.5418502202643172 25\n",
    "#...... confusion matrix:  [347 232 192 229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "addressed-sleeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cate(y_pred, X, tc, col):\n",
    "    cate_ = []\n",
    "    for i in range(X.shape[1]): \n",
    "        if len(np.unique(X3[:,i]))==2:\n",
    "            y0 = np.array(y_)[X[:,i]==0]\n",
    "            y1 = np.array(y_)[X[:,i]==1]\n",
    "        else: \n",
    "            y0 = np.array(y_)[X[:,i]<=np.mean(X3[:,i])]\n",
    "            y1 = np.array(y_)[X[:,i]>np.mean(X3[:,i])]\n",
    "        if i in col: \n",
    "            cate_.append(y1.mean() - y0.mean())\n",
    "            print('True Cause', y1.mean() - y0.mean(), tc[i])\n",
    "        else: \n",
    "            print('Covariate', y1.mean() - y0.mean(), 0)\n",
    "    \n",
    "    pehe = sum(pow(tc-cate_,2))/len(tc)\n",
    "    return cate_, pehe\n",
    "\n",
    "cate_, pehe = cate(y_, X3, tc[col] , range(len(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "naughty-harvest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Cause -0.024846314499687328 0.022801179154954943\n",
      "True Cause 0.040963765531613905 0.2728206833180276\n",
      "True Cause 0.0008479026512180354 -0.4867425772556366\n",
      "True Cause 0.04142869906065205 -0.3465873830592348\n",
      "True Cause 0.019657191127847418 -0.5741228935505409\n",
      "Covariate -0.007815411598412147 0\n",
      "Covariate 0.0016784553189072016 0\n",
      "Covariate 0.000679953137107725 0\n",
      "Covariate 0.011210015232946402 0\n",
      "Covariate 0.007189559216126407 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "powered-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-shadow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-policy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-domestic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
